{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a CNN model\n",
    "def define_cnn_model():\n",
    "    model = Sequential()\n",
    "    # 卷积层\n",
    "    model.add(Conv2D(32, (3, 3),\n",
    "                     activation='relu',\n",
    "                     kernel_initializer='he_uniform',\n",
    "                     padding='same',\n",
    "                     input_shape=(200, 200, 3)))\n",
    "    # 最大池化层\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    # Flatten 层\n",
    "    model.add(Flatten())\n",
    "    # 全连接层\n",
    "    model.add(Dense(128,\n",
    "                    activation='relu',\n",
    "                    kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # 编译模型\n",
    "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function of training a model\n",
    "def train_cnn_model():\n",
    "    # 实例化模型\n",
    "    model = define_cnn_model()\n",
    "    # 创建图片生成器\n",
    "    datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "    train_it = datagen.flow_from_directory(\n",
    "        './datasets/animals/',\n",
    "        class_mode='binary',\n",
    "        batch_size=64,\n",
    "        target_size=(200, 200))\n",
    "    # 训练模型\n",
    "    model.fit_generator(train_it,\n",
    "                        steps_per_epoch=len(train_it),\n",
    "                        epochs=20,\n",
    "                        verbose=1)\n",
    "    # 把模型保存到 results 文件夹\n",
    "    model.save(\"./results/basic_cnn_model_cat_dog.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Argument(s) not recognized: {'lr': 0.001}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     train_cnn_model()\n",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m, in \u001b[0;36mtrain_cnn_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_cnn_model\u001b[39m():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# 实例化模型\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     model \u001b[38;5;241m=\u001b[39m define_cnn_model()\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# 创建图片生成器\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 21\u001b[0m, in \u001b[0;36mdefine_cnn_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 编译模型\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m opt \u001b[38;5;241m=\u001b[39m SGD(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[0;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mopt,\n\u001b[0;32m     23\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     24\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\keras\\src\\optimizers\\sgd.py:60\u001b[0m, in \u001b[0;36mSGD.__init__\u001b[1;34m(self, learning_rate, momentum, nesterov, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     45\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     59\u001b[0m ):\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     61\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m     62\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m     63\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m     64\u001b[0m         clipnorm\u001b[38;5;241m=\u001b[39mclipnorm,\n\u001b[0;32m     65\u001b[0m         clipvalue\u001b[38;5;241m=\u001b[39mclipvalue,\n\u001b[0;32m     66\u001b[0m         global_clipnorm\u001b[38;5;241m=\u001b[39mglobal_clipnorm,\n\u001b[0;32m     67\u001b[0m         use_ema\u001b[38;5;241m=\u001b[39muse_ema,\n\u001b[0;32m     68\u001b[0m         ema_momentum\u001b[38;5;241m=\u001b[39mema_momentum,\n\u001b[0;32m     69\u001b[0m         ema_overwrite_frequency\u001b[38;5;241m=\u001b[39mema_overwrite_frequency,\n\u001b[0;32m     70\u001b[0m         loss_scale_factor\u001b[38;5;241m=\u001b[39mloss_scale_factor,\n\u001b[0;32m     71\u001b[0m         gradient_accumulation_steps\u001b[38;5;241m=\u001b[39mgradient_accumulation_steps,\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     73\u001b[0m     )\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(momentum, \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m momentum \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m momentum \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`momentum` must be a float between [0, 1].\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\optimizer.py:22\u001b[0m, in \u001b[0;36mTFOptimizer.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:37\u001b[0m, in \u001b[0;36mBaseOptimizer.__init__\u001b[1;34m(self, learning_rate, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `decay` is no longer supported and will be ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m     )\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument(s) not recognized: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     name \u001b[38;5;241m=\u001b[39m auto_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Argument(s) not recognized: {'lr': 0.001}"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_cnn_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
